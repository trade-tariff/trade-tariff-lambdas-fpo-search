name = "fpo-search-model-generator"
version = "0.0.2"
learning_rate = 0.001
max_epochs = 3
# target_memory_bytes = 20 * 1024 * 1024  # 20 MB in bytes (restricting to give us some headroom in the accelerator memory)
# embedding_size_bytes = 384 * 4  # 1.5 KiB per embedding (384 dimensions * 4 bytes per float32)
# batch_size = target_memory_bytes // embedding_size_bytes
model_batch_size = 13000
embedding_batch_size = 13000
embedding_cache_checkpoint = 50000
vague_terms_data_file = "reference_data/vague_terms.csv"
extra_data_file = "reference_data/extra_references.csv"
cn_data_file = "reference_data/CN2024_SelfText_EN_DE_FR.csv"
tradesets_data_dir = "raw_source_data/tradesets_descriptions"
device = "xla" # see Trn1 guidance https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/torch/torch-neuronx/programming-guide/training/pytorch-neuron-programming-guide.html
